import difflib
import logging
from functools import partial
from langdetect import detect
import spacy
import streamlit as st
from vertexai.preview.generative_models import Content, GenerationConfig, Part
from menu import help_page, return_home

from mypylib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
    to_contents_info,
)
from mypylib.html_constants import TIPPY_JS
from mypylib.html_fmt import display_grammar_errors
from mypylib.st_helper import (
    add_exercises_to_db,
    check_access,
    on_project_changed,
    configure_google_apis,
    setup_logger,
    update_sidebar_status,
)

# region é…ç½®

# åˆ›å»ºæˆ–è·å–loggerå¯¹è±¡


logger = logging.getLogger("streamlit")
setup_logger(logger)

st.set_page_config(
    page_title="å†™ä½œç»ƒä¹ ",
    page_icon="ğŸ„â€â™€ï¸",
    layout="wide",
)
return_home()
help_page()
check_access(False)
configure_google_apis()
on_project_changed("å†™ä½œç»ƒä¹ ")
add_exercises_to_db()
sidebar_status = st.sidebar.empty()

# endregion

# region ä¼šè¯

if "text-model" not in st.session_state:
    st.session_state["text-model"] = load_vertex_model("gemini-pro")

# Use the get method since the keys won't be in session_state on the first script run
if st.session_state.get("writing-clear"):
    st.session_state["writing-text"] = ""

# endregion

# region è¾¹æ 

# endregion


# region å‡½æ•°


def clear_text(key):
    st.session_state[key] = ""


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    "æ‚¨æ˜¯ä¸€åè‹±è¯­å†™ä½œè¾…å¯¼è€å¸ˆï¼Œæ‚¨çš„è§’è‰²ä¸ä»…æ˜¯æŒ‡å¯¼ï¼Œæ›´æ˜¯æ¿€å‘å­¦ç”Ÿçš„åˆ›ä½œæ½œåŠ›ã€‚æ‚¨éœ€è¦è€å¿ƒåœ°å¼•å¯¼å­¦ç”Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆã€‚é€šè¿‡æä¾›æç¤ºå’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä»–ä»¬åŸ¹å…»å’Œæå‡å†™ä½œæŠ€èƒ½ã€‚æ‚¨çš„å›å¤å§‹ç»ˆç”¨è‹±è¯­ï¼Œé™¤éå­¦ç”Ÿè¦æ±‚æ‚¨ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚å¦‚æœå­¦ç”Ÿæå‡ºä¸å†™ä½œæ— å…³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä»¥å©‰è½¬çš„æ–¹å¼å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["writing-chat"] = model.start_chat(history=history)


GRAMMAR_CHECK_TEMPLATE = """\
As an expert in English grammar, your task is to meticulously scrutinize the provided Article for any grammatical errors.
Step by step, complete the following:
1. Identify all grammatical inaccuracies in the article and rectify them accordingly.
2. In the event that the article is devoid of grammatical inaccuracies, yield an empty dictionary.
3. IMPORTANT: In the event of grammatical inaccuracies within the original text, each discrepancy should be annotated as follows: Utilize `~~` to denote the segment necessitating removal, and `[[` `]]` to signify the addition. In instances of substitutions, initially earmark the segment for removal, succeeded by the addition. This procedure will generate the "corrected" content, lucidly articulating the amendments predicated on the original text.
4. For each modification made, whether it be a replacement (consisting of one deletion and one addition), a pure addition, or a pure deletion, provide a corresponding explanation in text form. These text explanations should be formed into a list.
5. Output a dictionary with "corrected" (the corrected text) and "explanations" (the list of explanations) as keys.
6. Finally, output the dictionary in JSON format.

Grammatical errors include:
- Incorrect usage of tenses to describe past, present, or future events.
- Incorrect usage of singular or plural forms of nouns.
- Lack of agreement between the subject and verb in person or number.
- Incorrect usage of prepositions to indicate a specific relationship or location.
- Incorrect usage of conjunctions to connect two sentences or phrases.
- Incorrect usage of punctuation marks to separate sentences or phrases.
- Incorrect capitalization for proper nouns or at the beginning of sentences.
Please note that this list does not encompass spelling errors.

Example:
- Assume the original text is: 'I have many moeney in the past,I have not to work now.'
- The output dictionary should be:
    - corrected: "I ~~have~~ [[had]] many moeney in the past, so I ~~have not to~~ [[don't have to]] work now."
    - explanations: ["The past tense of 'have' is 'had'.", "The phrase 'have not to' is used to express necessity or obligation. In this context, it should be replaced with 'don't have to' to convey the idea of not being required to work."]

    
Article:{article}
"""


GRAMMAR_CHECK_CONFIG = {"max_output_tokens": 2048, "temperature": 0.0}


@st.cache_data(ttl=60 * 60 * 12, show_spinner="æ­£åœ¨æ£€æŸ¥è¯­æ³•...")
def check_grammar(article):
    # æ£€æŸ¥ article æ˜¯å¦ä¸ºè‹±æ–‡æ–‡æœ¬ [å­—ç¬¦æ•°é‡å°‘å®¹æ˜“è¢«é”™åˆ¤]
    if detect(article) != "en":
        return {"corrected": "è¯·ä½¿ç”¨è‹±è¯­å†™ä½œï¼", "explanations": []}

    prompt = GRAMMAR_CHECK_TEMPLATE.format(article=article)
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    return parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -è¯­æ³•æ£€æŸ¥",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**GRAMMAR_CHECK_CONFIG),
        stream=False,
        parser=partial(parse_json_string, prefix="```json", suffix="```"),
    )


# endregion

# region ä¸»ä½“

if "writing_chat_initialized" not in st.session_state:
    initialize_writing_chat()
    st.session_state["writing_chat_initialized"] = True

st.subheader("å†™ä½œç»ƒä¹ ", divider="rainbow", anchor="å†™ä½œç»ƒä¹ ")
st.markdown(
    "æœ¬å†™ä½œç»ƒä¹ æ—¨åœ¨å…¨é¢æå‡æ‚¨çš„å†™ä½œæŠ€å·§å’Œèƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›å¤šç§åœºæ™¯çš„å†™ä½œç»ƒä¹ ï¼Œä»¥å¸®åŠ©æ‚¨åœ¨å„ç§å®é™…æƒ…å¢ƒä¸­æå‡å†™ä½œæŠ€å·§ã€‚AIè¾…åŠ©åŠŸèƒ½å°†åœ¨æ‚¨çš„å†™ä½œè¿‡ç¨‹ä¸­æä¾›è¯­æ³•ã€è¯æ±‡ã€ä¸»é¢˜å’Œé£æ ¼çš„è¯„ä¼°æˆ–ä¿®æ­£ï¼Œç”šè‡³åœ¨éœ€è¦æ—¶æä¾›åˆ›ä½œçµæ„Ÿã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢æå‡æ‚¨çš„å†™ä½œèƒ½åŠ›çš„è¿‡ç¨‹ï¼Œæ—¨åœ¨è®©æ‚¨åœ¨å„ç§å†™ä½œåœºæ™¯ä¸­éƒ½èƒ½è‡ªå¦‚åº”å¯¹ã€‚"
)

w_btn_cols = st.columns(8)

# å¸ƒå±€
w_cols = st.columns(3)
HEIGHT = 600

w_cols[0].markdown("<h5 style='color: blue;'>æ‚¨çš„å†™ä½œç»ƒä¹ </h5>", unsafe_allow_html=True)

w_cols[0].text_area(
    "æ‚¨çš„å†™ä½œç»ƒä¹ ",
    max_chars=10000,
    key="writing-text",
    height=HEIGHT,
    placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    label_visibility="collapsed",
)
w_cols[1].markdown("<h5 style='color: green;'>AIå»ºè®®</h5>", unsafe_allow_html=True)
suggestions = w_cols[1].container(border=True, height=HEIGHT)

Assistant_Configuration = {
    "temperature": 0.2,
    "top_p": 1.0,
    "top_k": 32,
    "max_output_tokens": 1024,
}
assistant_config = GenerationConfig(**Assistant_Configuration)
with w_cols[2]:
    st.markdown("<h5 style='color: red;'>AIåŠ©æ•™</h5>", unsafe_allow_html=True)
    ai_tip_container = st.container(border=True, height=HEIGHT)
    with ai_tip_container:
        if prompt := st.chat_input("è¾“å…¥è¯·æ±‚ï¼Œè·å– AI å†™ä½œåŠ©æ‰‹çš„æ”¯æŒã€‚"):
            contents_info = [
                {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
            ]
            display_generated_content_and_update_token(
                "AIå†™ä½œåŠ©æ•™",
                "gemini-pro",
                st.session_state["writing-chat"].send_message,
                contents_info,
                assistant_config,
                stream=True,
                placeholder=ai_tip_container.empty(),
            )
            update_sidebar_status(sidebar_status)


if w_btn_cols[0].button(
    "åˆ·æ–°[:arrows_counterclockwise:]",
    key="writing-refresh",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹æ–°ä¸€è½®ç»ƒä¹ ã€‚",
):
    suggestions.empty()
    ai_tip_container.empty()
    initialize_writing_chat()
    st.rerun()

if w_btn_cols[1].button(
    "æ¸…é™¤[:wastebasket:]", key="writing-clear", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ¸…é™¤å†™ä½œç»ƒä¹ æ–‡æœ¬ã€‚"
):
    pass

if w_btn_cols[2].button(
    "è¯­æ³•[:triangular_ruler:]", key="grammar", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ£€æŸ¥è¯­æ³•é”™è¯¯ã€‚"
):
    suggestions.empty()
    result = check_grammar(st.session_state["writing-text"])
    suggestions.markdown(result["corrected"], unsafe_allow_html=True)
    suggestions.markdown(result["explanations"], unsafe_allow_html=True)

    html = display_grammar_errors(result["corrected"], result["explanations"])
    suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)
    update_sidebar_status(sidebar_status)

if w_btn_cols[3].button(
    "å•è¯[:abc:]", key="word", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ£€æŸ¥æ ‡ç‚¹ç¬¦å·å’Œæ‹¼å†™é”™è¯¯ã€‚"
):
    pass

if w_btn_cols[4].button(
    "æ¶¦è‰²[:art:]", key="polish", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæé«˜è¯æ±‡é‡å’Œå¥å¼å¤šæ ·æ€§ã€‚"
):
    pass

if w_btn_cols[5].button(
    "é€»è¾‘[:brain:]", key="logic", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ”¹å–„æ–‡ç« ç»“æ„å’Œé€»è¾‘ã€‚"
):
    # ä½ çš„æ–‡æœ¬
    text = "<p>è¿™æ˜¯ä¸€æ®µæ–‡æœ¬ã€‚</p>"

    # ä½¿ç”¨ st.code æ˜¾ç¤ºæ–‡æœ¬
    st.code(text, language="txt")

if w_btn_cols[6].button(
    "ä¿®æ­£[:wrench:]", key="revision", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ¥å—AIä¿®æ­£å»ºè®®ã€‚"
):
    pass


# endregion
