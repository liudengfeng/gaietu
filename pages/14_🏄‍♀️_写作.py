import difflib
import logging
from functools import partial

import spacy
import streamlit as st
from vertexai.preview.generative_models import Content, GenerationConfig, Part

from mypylib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
    to_contents_info,
)
from mypylib.html_constants import TIPPY_JS
from mypylib.html_fmt import display_grammar_errors
from mypylib.st_helper import (
    check_access,
    check_and_force_logout,
    configure_google_apis,
    setup_logger,
    update_sidebar_status,
)

# region é…ç½®

# åˆ›å»ºæˆ–è·å–loggerå¯¹è±¡


logger = logging.getLogger("streamlit")
setup_logger(logger)

st.set_page_config(
    page_title="å†™ä½œç»ƒä¹ ",
    page_icon="ğŸ„â€â™€ï¸",
    layout="wide",
)

check_access(False)
configure_google_apis()

sidebar_status = st.sidebar.empty()
check_and_force_logout(sidebar_status)

# endregion

# region ä¼šè¯

if "text-model" not in st.session_state:
    st.session_state["text-model"] = load_vertex_model("gemini-pro")

if "writing-text" not in st.session_state:
    st.session_state["writing-text"] = ""

# endregion

# region è¾¹æ 

# endregion


# region å‡½æ•°


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    "æ‚¨æ˜¯ä¸€åè‹±è¯­å†™ä½œè¾…å¯¼è€å¸ˆï¼Œä½ çš„è§’è‰²ä¸ä»…æ˜¯æŒ‡å¯¼ï¼Œæ›´æ˜¯æ¿€å‘å­¦ç”Ÿçš„åˆ›ä½œæ½œåŠ›ã€‚æ‚¨éœ€è¦è€å¿ƒåœ°å¼•å¯¼å­¦ç”Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆã€‚é€šè¿‡æä¾›æç¤ºå’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä»–ä»¬åŸ¹å…»å’Œæå‡å†™ä½œæŠ€èƒ½ã€‚æ‚¨çš„å›å¤å§‹ç»ˆç”¨è‹±è¯­ï¼Œé™¤éå­¦ç”Ÿè¦æ±‚æ‚¨ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚å¦‚æœå­¦ç”Ÿæå‡ºä¸å†™ä½œæ— å…³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä»¥å©‰è½¬çš„æ–¹å¼å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["writing-chat"] = model.start_chat(history=history)


GRAMMAR_CHECK_TEMPLATE = """\
As an expert in English grammar, your task is to rigorously review the grammar of the entire article provided below and complete the corrections.
Complete the following steps in sequence:
1. Identify all grammatical errors in the article and complete the corrections.
2. If there are no errors in the article, output an empty dictionary '{}'.
3. If there are errors, in the corrected text, surround the deleted text with `~~` and the added text with `[[ ]]`.
4. For each operation, provide a corresponding explanation. An operation can be a replacement (one deletion and one addition), a pure addition, or a pure deletion. Each operation should have one explanation.
5. Prepare a list of these explanations for the corrections made.
6. Output a dictionary with "corrected" (the corrected text in Markdown format) and "explanations" (the list of explanations) as keys.
7. Finally, output the dictionary in JSON format.

Article:
"""


GRAMMAR_CHECK_CONFIG = (
    {"max_output_tokens": 256, "temperature": 0.2, "top_p": 0.95, "top_k": 40},
)


@st.cache_data(ttl=60 * 60 * 24, show_spinner="æ­£åœ¨æ£€æŸ¥è¯­æ³•...")
def check_grammar(article):
    prompt = GRAMMAR_CHECK_TEMPLATE + "\n" + article
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    return parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -è¯­æ³•æ£€æŸ¥",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**GRAMMAR_CHECK_CONFIG[0]),
        stream=False,
        parser=partial(parse_json_string, prefix="```json", suffix="```"),
    )


# endregion

# region ä¸»ä½“

if "writing_chat_initialized" not in st.session_state:
    initialize_writing_chat()
    st.session_state["writing_chat_initialized"] = True

st.subheader("å†™ä½œç»ƒä¹ ", divider="rainbow", anchor="å†™ä½œç»ƒä¹ ")
st.markdown(
    "æœ¬å†™ä½œç»ƒä¹ æ—¨åœ¨å…¨é¢æå‡æ‚¨çš„å†™ä½œæŠ€å·§å’Œèƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›å¤šç§åœºæ™¯çš„å†™ä½œç»ƒä¹ ï¼Œä»¥å¸®åŠ©æ‚¨åœ¨å„ç§å®é™…æƒ…å¢ƒä¸­æå‡å†™ä½œæŠ€å·§ã€‚AIè¾…åŠ©åŠŸèƒ½å°†åœ¨æ‚¨çš„å†™ä½œè¿‡ç¨‹ä¸­æä¾›è¯­æ³•ã€è¯æ±‡ã€ä¸»é¢˜å’Œé£æ ¼çš„è¯„ä¼°æˆ–ä¿®æ­£ï¼Œç”šè‡³åœ¨éœ€è¦æ—¶æä¾›åˆ›ä½œçµæ„Ÿã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢æå‡æ‚¨çš„å†™ä½œèƒ½åŠ›çš„è¿‡ç¨‹ï¼Œæ—¨åœ¨è®©æ‚¨åœ¨å„ç§å†™ä½œåœºæ™¯ä¸­éƒ½èƒ½è‡ªå¦‚åº”å¯¹ã€‚"
)

# å¸ƒå±€
w_cols = st.columns(3)
HEIGHT = 500

w_cols[0].markdown("<h5 style='color: blue;'>æ‚¨çš„ä½œæ–‡</h5>", unsafe_allow_html=True)
article = w_cols[0].text_area(
    "æ‚¨çš„ä½œæ–‡",
    max_chars=10000,
    value=st.session_state["writing-text"],
    height=HEIGHT,
    placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    label_visibility="collapsed",
)
w_cols[1].markdown("<h5 style='color: green;'>AIå»ºè®®</h5>", unsafe_allow_html=True)
suggestions = w_cols[1].container(border=True, height=HEIGHT)
w_cols[2].markdown("<h5 style='color: red;'>AIåŠ©æ•™</h5>", unsafe_allow_html=True)
ai_tip_container = w_cols[2].container(border=True, height=HEIGHT)

w_btn_cols = st.columns(8)

if w_btn_cols[0].button(
    "åˆ·æ–°[:arrows_counterclockwise:]",
    key="refresh",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹æ–°ä¸€è½®ç»ƒä¹ ã€‚",
):
    st.session_state["writing-text"] = ""
    suggestions.empty()
    ai_tip_container.empty()
    initialize_writing_chat()
    st.rerun()


if w_btn_cols[1].button(
    "è¯­æ³•[:triangular_ruler:]", key="grammar", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ£€æŸ¥è¯­æ³•é”™è¯¯ã€‚"
):
    suggestions.empty()
    result = check_grammar(article)
    suggestions.write(type(result))
    # suggestions.write(result)
    # logger.info(result)

    suggestions.markdown(result["corrected"], unsafe_allow_html=True)
    # nlp = spacy.load("en_core_web_sm")
    # paragraphs = text.split("\n")
    html = ""
    # for paragraph in paragraphs:
    #     if paragraph.strip() == "":
    #         html += "<br/>"
    #         continue
    #     else:
    #         doc = nlp(paragraph)
    #     # sentences = list(doc.sents)
    #     for span in doc.sents:
    #         original = span.text
    #         check_dict = check_grammar(original)
    #         st.write(check_dict)
    #         # check_dict å¯èƒ½ä¸ºç©º {}
    #         html += display_grammar_errors(
    #             original,
    #             check_dict.get("corrected", original),
    #             check_dict.get("explanations", []),
    #         )
    #     html += "<br/>"

    suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)
    update_sidebar_status(sidebar_status)

if w_btn_cols[2].button(
    "å•è¯[:abc:]", key="word", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ£€æŸ¥æ ‡ç‚¹ç¬¦å·å’Œæ‹¼å†™é”™è¯¯ã€‚"
):
    pass

if w_btn_cols[3].button(
    "æ¶¦è‰²[:art:]", key="polish", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæé«˜è¯æ±‡é‡å’Œå¥å¼å¤šæ ·æ€§ã€‚"
):
    pass

if w_btn_cols[4].button(
    "é€»è¾‘[:brain:]", key="logic", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ”¹å–„æ–‡ç« ç»“æ„å’Œé€»è¾‘ã€‚"
):
    pass

Assistant_Configuration = {
    "temperature": 0.2,
    "top_p": 1.0,
    "top_k": 32,
    "max_output_tokens": 1024,
}
config = GenerationConfig(**Assistant_Configuration)

if prompt := st.chat_input("ä»AIå†™ä½œåŠ©æ•™å¤„è·å–æ”¯æŒ"):
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    ]
    display_generated_content_and_update_token(
        "AIå†™ä½œåŠ©æ•™",
        "gemini-pro",
        st.session_state["writing-chat"].send_message,
        contents_info,
        config,
        stream=True,
        placeholder=ai_tip_container.empty(),
    )
    update_sidebar_status(sidebar_status)

# endregion
