import difflib
import logging

import streamlit as st
from vertexai.preview.generative_models import Content, GenerationConfig, Part

from mypylib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
    to_contents_info,
)
from mypylib.html_constants import TIPPY_JS
from mypylib.st_helper import (
    check_access,
    check_and_force_logout,
    configure_google_apis,
    setup_logger,
    update_sidebar_status,
)

# region é…ç½®

# åˆ›å»ºæˆ–è·å–loggerå¯¹è±¡


logger = logging.getLogger("streamlit")
setup_logger(logger)

st.set_page_config(
    page_title="å†™ä½œç»ƒä¹ ",
    page_icon="ğŸ„â€â™€ï¸",
    layout="wide",
)

check_access(False)
configure_google_apis()

sidebar_status = st.sidebar.empty()
check_and_force_logout(sidebar_status)

# endregion

# region ä¼šè¯

if "text-model" not in st.session_state:
    st.session_state["text-model"] = load_vertex_model("gemini-pro")

# endregion

# region è¾¹æ 

# endregion


# region å‡½æ•°


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    "æ‚¨æ˜¯ä¸€åè‹±è¯­å†™ä½œè¾…å¯¼è€å¸ˆï¼Œä½ çš„è§’è‰²ä¸ä»…æ˜¯æŒ‡å¯¼ï¼Œæ›´æ˜¯æ¿€å‘å­¦ç”Ÿçš„åˆ›ä½œæ½œåŠ›ã€‚æ‚¨éœ€è¦è€å¿ƒåœ°å¼•å¯¼å­¦ç”Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆã€‚é€šè¿‡æä¾›æç¤ºå’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä»–ä»¬åŸ¹å…»å’Œæå‡å†™ä½œæŠ€èƒ½ã€‚æ‚¨çš„å›å¤å§‹ç»ˆç”¨è‹±è¯­ï¼Œé™¤éå­¦ç”Ÿè¦æ±‚æ‚¨ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚å¦‚æœå­¦ç”Ÿæå‡ºä¸å†™ä½œæ— å…³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä»¥å©‰è½¬çš„æ–¹å¼å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["writing-chat"] = model.start_chat(history=history)


GRAMMAR_CHECK_TEMPLATE = """\
You are an English grammar expert, please strictly check the grammar of each sentence. \
If a sentence is grammatically correct, represent it with an empty list '[]'. Otherwise, represent the check result with a list of dictionaries, each containing 'corrected' (the corrected sentence) and 'explanation' (the explanation of the correction) keys.\
All check results form a list. Output in JSON format."""

GRAMMAR_CHECK_CONFIG = (
    {"max_output_tokens": 256, "temperature": 0.2, "top_p": 0.95, "top_k": 40},
)


def check_grammar(paragraph):
    prompt = f"{paragraph} \n" + GRAMMAR_CHECK_TEMPLATE
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    return parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -è¯­æ³•æ£€æŸ¥",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**GRAMMAR_CHECK_CONFIG[0]),
        stream=False,
        # parser=parse_json_string,
    )


def display_grammar_errors(original, corrected, explanations):
    diff = difflib.ndiff(original.split(), corrected.split())
    diff = list(diff)  # ç”Ÿæˆåˆ—è¡¨

    result = []
    explanation_index = 0
    for i in range(len(diff)):
        explanation = (
            explanations[explanation_index].replace("'", "&#39;").replace('"', "&quot;")
            if explanation_index < len(explanations)
            else "No explanation available"
        )
        if diff[i][0] == "-":
            result.append(
                f"<del style='color:red;text-decoration: line-through' title='{explanation}'>{diff[i][2:]}</del>"
            )
            if i + 1 < len(diff) and diff[i + 1][0] == "+":
                result.append(
                    f"<ins style='color:blue;text-decoration: underline' title='{explanation}'>{diff[i + 1][2:]}</ins>"
                )
                i += 1  # è·³è¿‡ä¸‹ä¸€ä¸ªå…ƒç´ 
            explanation_index += 1
        elif diff[i][0] == "+":
            if i == 0 or diff[i - 1][0] != "-":
                result.append(
                    f"<ins style='color:green;text-decoration: underline' title='{explanation}'>{diff[i][2:]}</ins>"
                )
                explanation_index += 1
        else:
            result.append(f"<span>{diff[i][2:]}</span>")

    return " ".join(result)


# endregion

# region ä¸»ä½“

if "writing_chat_initialized" not in st.session_state:
    initialize_writing_chat()
    st.session_state["writing_chat_initialized"] = True

st.subheader("å†™ä½œç»ƒä¹ ", divider="rainbow", anchor="å†™ä½œç»ƒä¹ ")
st.markdown(
    "æœ¬å†™ä½œç»ƒä¹ æ—¨åœ¨å…¨é¢æå‡æ‚¨çš„å†™ä½œæŠ€å·§å’Œèƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›å¤šç§åœºæ™¯çš„å†™ä½œç»ƒä¹ ï¼Œä»¥å¸®åŠ©æ‚¨åœ¨å„ç§å®é™…æƒ…å¢ƒä¸­æå‡å†™ä½œæŠ€å·§ã€‚AIè¾…åŠ©åŠŸèƒ½å°†åœ¨æ‚¨çš„å†™ä½œè¿‡ç¨‹ä¸­æä¾›è¯­æ³•ã€è¯æ±‡ã€ä¸»é¢˜å’Œé£æ ¼çš„è¯„ä¼°æˆ–ä¿®æ­£ï¼Œç”šè‡³åœ¨éœ€è¦æ—¶æä¾›åˆ›ä½œçµæ„Ÿã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢æå‡æ‚¨çš„å†™ä½œèƒ½åŠ›çš„è¿‡ç¨‹ï¼Œæ—¨åœ¨è®©æ‚¨åœ¨å„ç§å†™ä½œåœºæ™¯ä¸­éƒ½èƒ½è‡ªå¦‚åº”å¯¹ã€‚"
)

# å¸ƒå±€
w_cols = st.columns(3)
HEIGHT = 500

w_cols[0].markdown("<h5 style='color: blue;'>æ‚¨çš„ä½œæ–‡</h5>", unsafe_allow_html=True)
text = w_cols[0].text_area(
    "æ‚¨çš„ä½œæ–‡",
    max_chars=10000,
    height=HEIGHT,
    placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    label_visibility="collapsed",
)
w_cols[1].markdown("<h5 style='color: green;'>AIå»ºè®®</h5>", unsafe_allow_html=True)
suggestions = w_cols[1].container(border=True, height=HEIGHT)
w_cols[2].markdown("<h5 style='color: red;'>AIåŠ©æ•™</h5>", unsafe_allow_html=True)
ai_tip_container = w_cols[2].container(border=True, height=HEIGHT)

w_btn_cols = st.columns(8)

if w_btn_cols[0].button(
    "åˆ·æ–°[:arrows_counterclockwise:]",
    key="refresh",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹æ–°ä¸€è½®ç»ƒä¹ ã€‚",
):
    text = ""
    suggestions.empty()
    ai_tip_container.empty()
    initialize_writing_chat()


# test_cases = [
#     {
#         "original": "I want to be a baseball player.",
#         "corrected": "I want to become a baseball player.",
#         "explanations": [
#             "Use 'become' instead of 'be' to indicate a change in status or condition."
#         ],
#     },
#     {
#         "original": "I want to a baseball player.",
#         "corrected": "I want to be a baseball player.",
#         "explanations": ["Missing verb 'be' in the sentence."],
#     },
#     {
#         "original": "I want to be be a baseball player.",
#         "corrected": "I want to be a baseball player.",
#         "explanations": ["Extra verb 'be' in the sentence."],
#     },
#     {
#         "original": "I has a baseball.",
#         "corrected": "I have a baseball.",
#         "explanations": ["Use 'have' instead of 'has' after 'I'."],
#     },
# ]
# test_cases.append(
#     {
#         "original": "I has a baseball in my home.",
#         "corrected": "I have a baseball at my home.",
#         "explanations": [
#             "Use 'have' instead of 'has' after 'I'.",
#             "Use 'at' instead of 'in' when referring to a location.",
#         ],
#     }
# )

if w_btn_cols[1].button(
    "è¯­æ³•[:abc:]", key="grammar", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹è¯­æ³•æ£€æŸ¥ã€‚"
):
    suggestions.empty()
    # paragraphs = text.split("\n")
    # for paragraph in paragraphs:
    #     result = check_grammar(paragraph)
    #     suggestions.write(result)
    html = ""
    for check in test_cases:
        html += display_grammar_errors(
            check["original"], check["corrected"], check["explanations"]
        )
    suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)
    update_sidebar_status(sidebar_status)


Assistant_Configuration = {
    "temperature": 0.2,
    "top_p": 1.0,
    "top_k": 32,
    "max_output_tokens": 1024,
}
config = GenerationConfig(**Assistant_Configuration)

if prompt := st.chat_input("ä»AIå†™ä½œåŠ©æ•™å¤„è·å–æ”¯æŒ"):
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    ]
    display_generated_content_and_update_token(
        "AIå†™ä½œåŠ©æ•™",
        "gemini-pro",
        st.session_state["writing-chat"].send_message,
        contents_info,
        config,
        stream=True,
        placeholder=ai_tip_container.empty(),
    )
    update_sidebar_status(sidebar_status)

# endregion
