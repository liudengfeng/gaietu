import difflib
import logging
import spacy
import streamlit as st
from vertexai.preview.generative_models import Content, GenerationConfig, Part

from mypylib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
    to_contents_info,
)
from mypylib.html_constants import TIPPY_JS
from mypylib.st_helper import (
    check_access,
    check_and_force_logout,
    configure_google_apis,
    setup_logger,
    update_sidebar_status,
)

# region é…ç½®

# åˆ›å»ºæˆ–è·å–loggerå¯¹è±¡


logger = logging.getLogger("streamlit")
setup_logger(logger)

st.set_page_config(
    page_title="å†™ä½œç»ƒä¹ ",
    page_icon="ğŸ„â€â™€ï¸",
    layout="wide",
)

check_access(False)
configure_google_apis()

sidebar_status = st.sidebar.empty()
check_and_force_logout(sidebar_status)

# endregion

# region ä¼šè¯

if "text-model" not in st.session_state:
    st.session_state["text-model"] = load_vertex_model("gemini-pro")

# endregion

# region è¾¹æ 

# endregion


# region å‡½æ•°


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    "æ‚¨æ˜¯ä¸€åè‹±è¯­å†™ä½œè¾…å¯¼è€å¸ˆï¼Œä½ çš„è§’è‰²ä¸ä»…æ˜¯æŒ‡å¯¼ï¼Œæ›´æ˜¯æ¿€å‘å­¦ç”Ÿçš„åˆ›ä½œæ½œåŠ›ã€‚æ‚¨éœ€è¦è€å¿ƒåœ°å¼•å¯¼å­¦ç”Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆã€‚é€šè¿‡æä¾›æç¤ºå’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä»–ä»¬åŸ¹å…»å’Œæå‡å†™ä½œæŠ€èƒ½ã€‚æ‚¨çš„å›å¤å§‹ç»ˆç”¨è‹±è¯­ï¼Œé™¤éå­¦ç”Ÿè¦æ±‚æ‚¨ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚å¦‚æœå­¦ç”Ÿæå‡ºä¸å†™ä½œæ— å…³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä»¥å©‰è½¬çš„æ–¹å¼å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["writing-chat"] = model.start_chat(history=history)


GRAMMAR_CHECK_TEMPLATE = """\
You are an expert in English grammar, please strictly check the grammar of each sentence in the following text.\
If a sentence is grammatically correct, represent it with an empty list '[]'. Otherwise, each grammatical error in the sentence should be represented with a dictionary containing 'corrected' (the corrected sentence) and 'explanation' (the explanation of the correction) keys. The result of the grammar check for a sentence should be represented as a list of dictionaries.\
Then, these lists are combined into a list. Output in JSON format.\

text:
"""

GRAMMAR_CHECK_CONFIG = (
    {"max_output_tokens": 256, "temperature": 0.2, "top_p": 0.95, "top_k": 40},
)


def check_grammar(paragraph):
    prompt = GRAMMAR_CHECK_TEMPLATE + paragraph
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    return parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -è¯­æ³•æ£€æŸ¥",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**GRAMMAR_CHECK_CONFIG[0]),
        stream=False,
        # parser=parse_json_string,
    )


def display_grammar_errors(original, corrected, explanation):
    diff = difflib.ndiff(original.split(), corrected.split())
    diff = list(diff)  # ç”Ÿæˆåˆ—è¡¨

    result = []
    for i in range(len(diff)):
        if diff[i][0] == "-":
            result.append(
                f"<del style='color:red;text-decoration: line-through' title='{explanation}'>{diff[i][2:].lstrip()}</del>"
            )
            if i + 1 < len(diff) and diff[i + 1][0] == "+":
                result.append(
                    f"<ins style='color:blue;text-decoration: underline' title='{explanation}'>{diff[i + 1][2:].lstrip()}</ins>"
                )
                i += 1  # è·³è¿‡ä¸‹ä¸€ä¸ªå…ƒç´ 
        elif diff[i][0] == "+":
            if i == 0 or diff[i - 1][0] != "-":
                result.append(
                    f"<ins style='color:green;text-decoration: underline' title='{explanation}'>{diff[i][2:].lstrip()}</ins>"
                )
        else:
            result.append(f"<span>{diff[i][2:].lstrip()}</span>")

    return " ".join(result)


# endregion

# region ä¸»ä½“

if "writing_chat_initialized" not in st.session_state:
    initialize_writing_chat()
    st.session_state["writing_chat_initialized"] = True

st.subheader("å†™ä½œç»ƒä¹ ", divider="rainbow", anchor="å†™ä½œç»ƒä¹ ")
st.markdown(
    "æœ¬å†™ä½œç»ƒä¹ æ—¨åœ¨å…¨é¢æå‡æ‚¨çš„å†™ä½œæŠ€å·§å’Œèƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›å¤šç§åœºæ™¯çš„å†™ä½œç»ƒä¹ ï¼Œä»¥å¸®åŠ©æ‚¨åœ¨å„ç§å®é™…æƒ…å¢ƒä¸­æå‡å†™ä½œæŠ€å·§ã€‚AIè¾…åŠ©åŠŸèƒ½å°†åœ¨æ‚¨çš„å†™ä½œè¿‡ç¨‹ä¸­æä¾›è¯­æ³•ã€è¯æ±‡ã€ä¸»é¢˜å’Œé£æ ¼çš„è¯„ä¼°æˆ–ä¿®æ­£ï¼Œç”šè‡³åœ¨éœ€è¦æ—¶æä¾›åˆ›ä½œçµæ„Ÿã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢æå‡æ‚¨çš„å†™ä½œèƒ½åŠ›çš„è¿‡ç¨‹ï¼Œæ—¨åœ¨è®©æ‚¨åœ¨å„ç§å†™ä½œåœºæ™¯ä¸­éƒ½èƒ½è‡ªå¦‚åº”å¯¹ã€‚"
)

# å¸ƒå±€
w_cols = st.columns(3)
HEIGHT = 500

w_cols[0].markdown("<h5 style='color: blue;'>æ‚¨çš„ä½œæ–‡</h5>", unsafe_allow_html=True)
text = w_cols[0].text_area(
    "æ‚¨çš„ä½œæ–‡",
    max_chars=10000,
    height=HEIGHT,
    placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    label_visibility="collapsed",
)
w_cols[1].markdown("<h5 style='color: green;'>AIå»ºè®®</h5>", unsafe_allow_html=True)
suggestions = w_cols[1].container(border=True, height=HEIGHT)
w_cols[2].markdown("<h5 style='color: red;'>AIåŠ©æ•™</h5>", unsafe_allow_html=True)
ai_tip_container = w_cols[2].container(border=True, height=HEIGHT)

w_btn_cols = st.columns(8)

if w_btn_cols[0].button(
    "åˆ·æ–°[:arrows_counterclockwise:]",
    key="refresh",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹æ–°ä¸€è½®ç»ƒä¹ ã€‚",
):
    text = ""
    suggestions.empty()
    ai_tip_container.empty()
    initialize_writing_chat()


test_cases = [
    {
        "original": "I has a baseball.",
        "corrected": "I have a baseball.",
        "explanation": "Use 'have' instead of 'has' after 'I'.",
    },
    {
        "original": "I has a baseball in my home.",
        "corrected": "I have a baseball at my home.",
        "explanation": "Use 'have' instead of 'has' after 'I'. Use 'at' instead of 'in' when referring to a location.",
    },
    {
        "original": "She don't like apples.",
        "corrected": "She doesn't like apples.",
        "explanation": "Use 'doesn't' instead of 'don't' after 'She'.",
    },
    {
        "original": "He can plays the guitar.",
        "corrected": "He can play the guitar.",
        "explanation": "Use 'play' instead of 'plays' after 'can'.",
    },
    {
        "original": "He can play play the guitar.",
        "corrected": "He can play the guitar.",
        "explanation": "Remove the extra 'play' before 'play'.",
    },
    {
        "original": "They enjoys playing football.",
        "corrected": "They enjoy playing football.",
        "explanation": "Use 'enjoy' instead of 'enjoys' after 'They'.",
    },
    {
        "original": "They enjoy football.",
        "corrected": "They enjoy playing football.",
        "explanation": "Add 'playing' before 'football' to indicate the action.",
    },
]


if w_btn_cols[1].button(
    "è¯­æ³•[:abc:]", key="grammar", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹è¯­æ³•æ£€æŸ¥ã€‚"
):
    suggestions.empty()
    for test_case in test_cases:
        suggestions.markdown(
            display_grammar_errors(
                test_case["original"], test_case["corrected"], test_case["explanation"]
            ),
            unsafe_allow_html=True,
        )

    # nlp = spacy.load("en_core_web_sm")
    # paragraphs = text.split("\n")
    # paragraphs_check = []
    # for paragraph in paragraphs:
    #     paragraphs_check.append(check_grammar(paragraph))
    # html = ""
    # for paragraph, check in zip(paragraphs, paragraphs_check):
    #     sentences = paragraph.split(".")
    #     doc = nlp(paragraph)
    #     sentences = list(doc.sents)
    #     for original, check_dict in zip(sentences, check):
    #         html += display_grammar_errors(
    #             original, check_dict["corrected"], check_dict["explanation"]
    #         )
    # # suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)
    # update_sidebar_status(sidebar_status)


Assistant_Configuration = {
    "temperature": 0.2,
    "top_p": 1.0,
    "top_k": 32,
    "max_output_tokens": 1024,
}
config = GenerationConfig(**Assistant_Configuration)

if prompt := st.chat_input("ä»AIå†™ä½œåŠ©æ•™å¤„è·å–æ”¯æŒ"):
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    ]
    display_generated_content_and_update_token(
        "AIå†™ä½œåŠ©æ•™",
        "gemini-pro",
        st.session_state["writing-chat"].send_message,
        contents_info,
        config,
        stream=True,
        placeholder=ai_tip_container.empty(),
    )
    update_sidebar_status(sidebar_status)

# endregion
