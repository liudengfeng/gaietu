import difflib
import logging
import spacy
import streamlit as st
from vertexai.preview.generative_models import Content, GenerationConfig, Part

from mypylib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
    to_contents_info,
)
from mypylib.html_constants import TIPPY_JS
from mypylib.html_fmt import display_grammar_errors
from mypylib.st_helper import (
    check_access,
    check_and_force_logout,
    configure_google_apis,
    setup_logger,
    update_sidebar_status,
)

# region é…ç½®

# åˆ›å»ºæˆ–è·å–loggerå¯¹è±¡


logger = logging.getLogger("streamlit")
setup_logger(logger)

st.set_page_config(
    page_title="å†™ä½œç»ƒä¹ ",
    page_icon="ğŸ„â€â™€ï¸",
    layout="wide",
)

check_access(False)
configure_google_apis()

sidebar_status = st.sidebar.empty()
check_and_force_logout(sidebar_status)

# endregion

# region ä¼šè¯

if "text-model" not in st.session_state:
    st.session_state["text-model"] = load_vertex_model("gemini-pro")

if "writing-text" not in st.session_state:
    st.session_state["writing-text"] = ""

# endregion

# region è¾¹æ 

# endregion


# region å‡½æ•°


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    "æ‚¨æ˜¯ä¸€åè‹±è¯­å†™ä½œè¾…å¯¼è€å¸ˆï¼Œä½ çš„è§’è‰²ä¸ä»…æ˜¯æŒ‡å¯¼ï¼Œæ›´æ˜¯æ¿€å‘å­¦ç”Ÿçš„åˆ›ä½œæ½œåŠ›ã€‚æ‚¨éœ€è¦è€å¿ƒåœ°å¼•å¯¼å­¦ç”Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆã€‚é€šè¿‡æä¾›æç¤ºå’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä»–ä»¬åŸ¹å…»å’Œæå‡å†™ä½œæŠ€èƒ½ã€‚æ‚¨çš„å›å¤å§‹ç»ˆç”¨è‹±è¯­ï¼Œé™¤éå­¦ç”Ÿè¦æ±‚æ‚¨ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚å¦‚æœå­¦ç”Ÿæå‡ºä¸å†™ä½œæ— å…³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä»¥å©‰è½¬çš„æ–¹å¼å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["writing-chat"] = model.start_chat(history=history)


GRAMMAR_CHECK_TEMPLATE = """\
As an expert in English grammar, your task is to rigorously review the grammar of the sentence provided below.
Grammar Checking Process:
Should you find any grammatical errors in the sentence, please correct them and provide explanations for each correction.
The result of the grammar check should be a dictionary, which includes two keys: 'corrected', representing the corrected sentence, and 'explanations', a list of explanations (strings) for each correction.
If the sentence is grammatically correct, the result should be an empty dictionary '{}'. 

Sentence:
"""

GRAMMAR_CHECK_CONFIG = (
    {"max_output_tokens": 256, "temperature": 0.2, "top_p": 0.95, "top_k": 40},
)


@st.cache_data(ttl=60 * 60 * 24, show_spinner="æ­£åœ¨æ£€æŸ¥è¯­æ³•...")
def check_grammar(sentence):
    prompt = GRAMMAR_CHECK_TEMPLATE + "\n" + sentence
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    return parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -è¯­æ³•æ£€æŸ¥",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**GRAMMAR_CHECK_CONFIG[0]),
        stream=False,
        parser=parse_json_string,
    )


# endregion

# region ä¸»ä½“

if "writing_chat_initialized" not in st.session_state:
    initialize_writing_chat()
    st.session_state["writing_chat_initialized"] = True

st.subheader("å†™ä½œç»ƒä¹ ", divider="rainbow", anchor="å†™ä½œç»ƒä¹ ")
st.markdown(
    "æœ¬å†™ä½œç»ƒä¹ æ—¨åœ¨å…¨é¢æå‡æ‚¨çš„å†™ä½œæŠ€å·§å’Œèƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›å¤šç§åœºæ™¯çš„å†™ä½œç»ƒä¹ ï¼Œä»¥å¸®åŠ©æ‚¨åœ¨å„ç§å®é™…æƒ…å¢ƒä¸­æå‡å†™ä½œæŠ€å·§ã€‚AIè¾…åŠ©åŠŸèƒ½å°†åœ¨æ‚¨çš„å†™ä½œè¿‡ç¨‹ä¸­æä¾›è¯­æ³•ã€è¯æ±‡ã€ä¸»é¢˜å’Œé£æ ¼çš„è¯„ä¼°æˆ–ä¿®æ­£ï¼Œç”šè‡³åœ¨éœ€è¦æ—¶æä¾›åˆ›ä½œçµæ„Ÿã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢æå‡æ‚¨çš„å†™ä½œèƒ½åŠ›çš„è¿‡ç¨‹ï¼Œæ—¨åœ¨è®©æ‚¨åœ¨å„ç§å†™ä½œåœºæ™¯ä¸­éƒ½èƒ½è‡ªå¦‚åº”å¯¹ã€‚"
)

# å¸ƒå±€
w_cols = st.columns(3)
HEIGHT = 500

w_cols[0].markdown("<h5 style='color: blue;'>æ‚¨çš„ä½œæ–‡</h5>", unsafe_allow_html=True)
text = w_cols[0].text_area(
    "æ‚¨çš„ä½œæ–‡",
    max_chars=10000,
    value=st.session_state["writing-text"],
    height=HEIGHT,
    placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    label_visibility="collapsed",
)
w_cols[1].markdown("<h5 style='color: green;'>AIå»ºè®®</h5>", unsafe_allow_html=True)
suggestions = w_cols[1].container(border=True, height=HEIGHT)
w_cols[2].markdown("<h5 style='color: red;'>AIåŠ©æ•™</h5>", unsafe_allow_html=True)
ai_tip_container = w_cols[2].container(border=True, height=HEIGHT)

w_btn_cols = st.columns(8)

if w_btn_cols[0].button(
    "åˆ·æ–°[:arrows_counterclockwise:]",
    key="refresh",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹æ–°ä¸€è½®ç»ƒä¹ ã€‚",
):
    st.session_state["writing-text"] = ""
    suggestions.empty()
    ai_tip_container.empty()
    initialize_writing_chat()
    st.rerun()


if w_btn_cols[1].button(
    "è¯­æ³•[:abc:]", key="grammar", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹è¯­æ³•æ£€æŸ¥ã€‚"
):
    suggestions.empty()
    nlp = spacy.load("en_core_web_sm")
    paragraphs = text.split("\n")
    html = ""
    for paragraph in paragraphs:
        if paragraph.strip() == "":
            html += "<br/>"
            continue
        else:
            doc = nlp(paragraph)
        # sentences = list(doc.sents)
        for span in doc.sents:
            original = span.text
            check_dict = check_grammar(original)
            st.write(check_dict)
            # check_dict å¯èƒ½ä¸ºç©º {}
            html += display_grammar_errors(
                original,
                check_dict.get("corrected", original),
                check_dict.get("explanations", []),
            )
        html += "<br/>"

    suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)
    update_sidebar_status(sidebar_status)


Assistant_Configuration = {
    "temperature": 0.2,
    "top_p": 1.0,
    "top_k": 32,
    "max_output_tokens": 1024,
}
config = GenerationConfig(**Assistant_Configuration)

if prompt := st.chat_input("ä»AIå†™ä½œåŠ©æ•™å¤„è·å–æ”¯æŒ"):
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    ]
    display_generated_content_and_update_token(
        "AIå†™ä½œåŠ©æ•™",
        "gemini-pro",
        st.session_state["writing-chat"].send_message,
        contents_info,
        config,
        stream=True,
        placeholder=ai_tip_container.empty(),
    )
    update_sidebar_status(sidebar_status)

# endregion
