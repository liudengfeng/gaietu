import json
import re
from datetime import datetime, timedelta

import pytz
import streamlit as st
import streamlit.components.v1 as components
from streamlit_mic_recorder import mic_recorder

from mypylib.azure_pronunciation_assessment import adjust_display_by_reference_text
from mypylib.constants import CEFR_LEVEL_MAPS, CEFR_LEVEL_TOPIC, VOICES_FP
from mypylib.db_model import LearningTime
from mypylib.google_ai import generate_pronunciation_assessment_text, load_vertex_model
from mypylib.nivo_charts import gen_radar
from mypylib.st_helper import (
    TOEKN_HELP_INFO,
    autoplay_audio_and_display_text,
    check_access,
    check_and_force_logout,
    configure_google_apis,
    display_pronunciation_result,
    format_token_count,
    get_synthesis_speech,
    left_paragraph_aligned_text,
    on_page_to,
    process_dialogue_text,
    process_learning_record,
    pronunciation_assessment_for,
    view_pronunciation_assessment_legend,
    view_word_assessment,
)
from mypylib.word_utils import audio_autoplay_elem

# region é…ç½®

st.set_page_config(
    page_title="èƒ½åŠ›è¯„ä¼°",
    page_icon=":bookmark:",
    layout="wide",
)

check_access(False)
on_page_to("èƒ½åŠ›è¯„ä¼°")
configure_google_apis()

menu_items = ["å‘éŸ³è¯„ä¼°", "å£è¯­èƒ½åŠ›", "å†™ä½œè¯„ä¼°"]
menu_emojis = ["ğŸ”Š", "ğŸ—£ï¸", "âœï¸"]
menu_opts = [f"{e} {i}" for i, e in zip(menu_items, menu_emojis)]
menu = st.sidebar.selectbox("èœå•", menu_opts, help="é€‰æ‹©ä½ è¦ç»ƒä¹ çš„é¡¹ç›®")

st.sidebar.divider()
sidebar_status = st.sidebar.empty()
check_and_force_logout(sidebar_status)

sidebar_status.markdown(
    f"""ä»¤ç‰Œï¼š{st.session_state.current_token_count} ç´¯è®¡ï¼š{format_token_count(st.session_state.total_token_count)}""",
    help=TOEKN_HELP_INFO,
)

if "text_model" not in st.session_state:
    st.session_state["text_model"] = load_vertex_model("gemini-pro")

if "m_voices" not in st.session_state and "fm_voices" not in st.session_state:
    with open(VOICES_FP, "r", encoding="utf-8") as f:
        voices = json.load(f)["en-US"]
    st.session_state["m_voices"] = [v for v in voices if v[1] == "Male"]
    st.session_state["fm_voices"] = [v for v in voices if v[1] == "Female"]

if "pa-learning-times" not in st.session_state:
    st.session_state["pa-learning-times"] = 0

if "pa-idx" not in st.session_state:
    st.session_state["pa-idx"] = -1

if "pa-text" not in st.session_state:
    st.session_state["pa-text"] = ""

if "pa-current-text" not in st.session_state:
    st.session_state["pa-current-text"] = ""

if "pa-assessment" not in st.session_state:
    st.session_state["pa-assessment"] = {}

# endregion

# region å‡½æ•°


def on_prev_btn_click(key):
    st.session_state[key] -= 1


def on_next_btn_click(key):
    st.session_state[key] += 1


def create_learning_record(
    project,
    difficulty,
    selected_scenario,
    words,
):
    record = LearningTime(
        phone_number=st.session_state.dbi.cache["user_info"]["phone_number"],
        project=project,
        content=f"{difficulty}-{selected_scenario}",
        word_count=words,
    )
    return record


@st.cache_data(ttl=60 * 60 * 24, show_spinner="AIæ­£åœ¨ç”Ÿæˆå‘éŸ³è¯„ä¼°æ–‡æœ¬ï¼Œè¯·ç¨å€™...")
def generate_pronunciation_assessment_text_for(scenario_category, difficulty):
    return generate_pronunciation_assessment_text(
        st.session_state["text_model"], scenario_category, difficulty
    )


def display_pronunciation_assessment_words(container, text_key, assessment_key):
    # å»æ‰ ** åŠ é»‘æ ‡è®°
    text = st.session_state[text_key].replace("**", "")
    words = st.session_state[assessment_key].get("recognized_words", [])
    container.markdown("##### è¯„ä¼°ç»“æœ")
    if len(words) == 0:
        return
    adjusted = adjust_display_by_reference_text(text, words)
    with container:
        view_word_assessment(adjusted)


def view_radar(score_key, item_maps):
    # é›·è¾¾å›¾
    data_tb = {
        key: st.session_state.get(score_key, {})
        .get("pronunciation_result", {})
        .get(key, 0)
        for key in item_maps.keys()
    }
    gen_radar(data_tb, item_maps, 320)


def play_and_record_text(voice_style, difficulty, selected_scenario):
    text = st.session_state["pa-text"]
    if not text:
        return
    style = voice_style[0]

    with st.spinner(f"ä½¿ç”¨ Azure å°†æ–‡æœ¬åˆæˆè¯­éŸ³..."):
        result = get_synthesis_speech(text, style)

    audio_html = audio_autoplay_elem(result["audio_data"], fmt="wav")
    components.html(audio_html)

    # è®°å½•å­¦ä¹ æ—¶é•¿
    word_count = len(re.findall(r"\b\w+\b", text))
    record = create_learning_record("å‘éŸ³è¯„ä¼°", difficulty, selected_scenario, word_count)
    process_learning_record(record, "pa-learning-times")


def display_assessment_text(pa_text_container):
    with pa_text_container:
        title = "è¯„ä¼°æ–‡æœ¬"
        text = st.session_state["pa-text"]
        if text:
            idx = st.session_state["pa-idx"]
            words = []
            if idx == -1:
                words = st.session_state["pa-text"].split()
                title = f"è¯„ä¼°å…¨æ–‡[å•è¯æ€»æ•°ï¼š{len(words)}]"
            else:
                words = st.session_state["pa-current-text"].split()
                title = f"è¯„ä¼°æ®µè½[å•è¯æ€»æ•°ï¼š{len(words)}]"

            st.markdown(f"##### {title}")

            if idx == -1:
                st.markdown(text, unsafe_allow_html=True)
            else:
                st.markdown(st.session_state["pa-current-text"], unsafe_allow_html=True)
        else:
            st.markdown(f"##### {title}")


# endregion

# region å‘éŸ³è¯„ä¼°

if menu and menu.endswith("å‘éŸ³è¯„ä¼°"):
    difficulty = st.sidebar.selectbox(
        "CEFRç­‰çº§",
        list(CEFR_LEVEL_MAPS.keys()),
        key="listening-difficulty",
        index=0,
        format_func=lambda x: f"{x}({CEFR_LEVEL_MAPS[x]})",
        placeholder="è¯·é€‰æ‹©CEFRç­‰çº§",
    )

    voice_gender = st.sidebar.radio("é€‰æ‹©åˆæˆå£°éŸ³çš„æ€§åˆ«", ("ç”·æ€§", "å¥³æ€§"), index=0)

    if voice_gender == "ç”·æ€§":
        voice_style_options = st.session_state["m_voices"]
    else:
        voice_style_options = st.session_state["fm_voices"]

    voice_style = st.sidebar.selectbox(
        "åˆæˆå£°éŸ³é£æ ¼",
        voice_style_options,
        help="âœ¨ é€‰æ‹©æ‚¨å–œæ¬¢çš„è¯­éŸ³é£æ ¼",
        format_func=lambda x: f"{x[2]}",  # type: ignore
    )

    st.subheader("å‘éŸ³è¯„ä¼°", divider="rainbow", anchor="å‘éŸ³è¯„ä¼°")
    st.markdown(
        "åœ¨é€‰æ‹©äº† CEFR ç­‰çº§å’Œå‘éŸ³è¯„ä¼°çš„åœºæ™¯ç±»åˆ«ä¹‹åï¼Œç‚¹å‡» 'åˆ·æ–°[ğŸ”„]' æŒ‰é’®æ¥ç”Ÿæˆç”¨äºå‘éŸ³è¯„ä¼°çš„æ–‡æœ¬ã€‚ç„¶åï¼Œç‚¹å‡» 'å½•éŸ³[â¸ï¸]' æŒ‰é’®ï¼ŒæŒ‰ç…§ç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œæœ—è¯»ã€‚å®Œæˆæœ—è¯»åï¼Œç‚¹å‡» 'è¯„ä¼°[ğŸ”–]' æŒ‰é’®ï¼Œç³»ç»Ÿå°†å¯¹ä½ çš„å‘éŸ³è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç”Ÿæˆå‘éŸ³è¯„ä¼°æŠ¥å‘Šã€‚"
    )
    scenario_category = st.selectbox(
        "é€‰æ‹©åœºæ™¯ç±»åˆ«",
        CEFR_LEVEL_TOPIC[difficulty],
        index=0,
        key="scenario_category",
        placeholder="è¯·é€‰æ‹©åœºæ™¯ç±»åˆ«",
    )

    pa_report_container = st.container(border=True)
    replay_text_placeholder = st.empty()
    pa_cols = st.columns(8)

    pa_refresh_btn = pa_cols[0].button(
        "åˆ·æ–°[:arrows_counterclockwise:]",
        key="refresh_pronunciation_assessment_text",
        help="ç‚¹å‡»æŒ‰é’®ï¼Œç”Ÿæˆå‘éŸ³è¯„ä¼°æ–‡æœ¬",
    )
    prev_btn = pa_cols[1].button(
        "ä¸Šä¸€[:leftwards_arrow_with_hook:]",
        key="ra-prev",
        help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œåˆ‡æ¢åˆ°ä¸Šä¸€æ®µè½ã€‚",
        on_click=on_prev_btn_click,
        args=("pa-idx",),
        disabled=st.session_state["pa-idx"] < 0,
    )
    next_btn = pa_cols[2].button(
        "ä¸‹ä¸€[:arrow_right_hook:]",
        key="ra-next",
        help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€æ®µè½ã€‚",
        on_click=on_next_btn_click,
        args=("pa-idx",),
        disabled=st.session_state["pa-idx"]
        == len(
            [line for line in st.session_state["pa-text"].splitlines() if line.strip()]
        )
        - 1,
    )
    synthetic_audio_replay_button = pa_cols[3].button(
        "æ”¶å¬[:headphones:]",
        key="pa-replay",
        help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ”¶å¬æ–‡æœ¬çš„åˆæˆè¯­éŸ³ã€‚",
        disabled=st.session_state["pa-current-text"] == "",
    )
    audio_key = "pa-mic-recorder"
    audio_session_output_key = f"{audio_key}-output"
    with pa_cols[4]:
        audio_info = mic_recorder(
            start_prompt="å½•éŸ³[â¸ï¸]",
            stop_prompt="åœæ­¢[ğŸ”´]",
            key=audio_key,
        )
    pa_pro_btn = pa_cols[5].button(
        "è¯„ä¼°[ğŸ”–]",
        disabled=not audio_info or st.session_state["pa-current-text"] == "",
        key="pa-evaluation-btn",
        help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹å‘éŸ³è¯„ä¼°ã€‚",
    )
    audio_playback_button = pa_cols[6].button(
        "å›æ”¾[â–¶ï¸]",
        disabled=not audio_info or st.session_state["pa-current-text"] == "",
        key="pa-play-btn",
        help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ’­æ”¾æ‚¨çš„è·Ÿè¯»å½•éŸ³ã€‚",
    )
    # å·¦ä¾§æ˜¾ç¤ºå‘éŸ³è¯„ä¼°æ–‡æœ¬
    # å³ä¾§æ˜¾ç¤ºè¯„ä¼°å†…å®¹
    content_cols = st.columns([6, 6, 2])
    pa_text_container = content_cols[0].container(border=True)
    pa_words_container = content_cols[1].container(border=True)
    legend_container = content_cols[2].container(border=True)

    with legend_container:
        st.markdown("##### å›¾ä¾‹")
        view_pronunciation_assessment_legend()

    if pa_refresh_btn:
        st.session_state["pa-text"] = generate_pronunciation_assessment_text_for(
            scenario_category, difficulty
        )
        st.session_state["pa-idx"] = -1
        st.session_state["pa-current-text"] = ""
        st.rerun()

    if prev_btn or next_btn:
        text = st.session_state["pa-text"]
        paragraphs = [line for line in text.splitlines() if line.strip()]
        st.session_state["pa-current-text"] = paragraphs[st.session_state["pa-idx"]]

    display_assessment_text(pa_text_container)

    if pa_pro_btn and audio_info is not None:
        # å»æ‰å‘è¨€è€…çš„åå­—
        idx = st.session_state["pa-idx"]
        if idx != -1:
            text = st.session_state["pa-text"]
            paragraphs = [line for line in text.splitlines() if line.strip()]
        else:
            st.error("è¯„ä¼°å…¨æ–‡ä¸å¯è¡Œï¼Œè¯·é€‰æ‹©æ®µè½è¿›è¡Œè¯„ä¼°ã€‚")
            st.stop()

        reference_text = process_dialogue_text(paragraphs[idx])

        # start = datetime.now(pytz.UTC)
        st.session_state["pa-assessment"] = pronunciation_assessment_for(
            audio_info,
            reference_text,
        )

        # # TODO:ç®¡ç†å¾…å¤„ç†ä»»åŠ¡åˆ—è¡¨
        # # åˆ›å»ºä¸€ä¸ªç©ºçš„å¾…å¤„ç†ä»»åŠ¡åˆ—è¡¨
        # tasks = []
        # # éå†å‘éŸ³è¯„ä¼°ç»“æœ
        # for word in st.session_state["pa-assessment"].get("recognized_words", []):
        #     # å¦‚æœå•è¯çš„å‘éŸ³é”™è¯¯ï¼Œå°†å®ƒæ·»åŠ åˆ°å¾…å¤„ç†ä»»åŠ¡åˆ—è¡¨ä¸­
        #     if word.get("error_type") == "Mispronunciation":
        #         tasks.append(word.word)

    if audio_playback_button and audio_info and st.session_state["pa-assessment"]:
        autoplay_audio_and_display_text(
            replay_text_placeholder,
            audio_info["bytes"],
            st.session_state["pa-assessment"]["recognized_words"],
        )

    if synthetic_audio_replay_button:
        idx = st.session_state["pa-idx"]
        play_and_record_text(
            voice_style,
            difficulty,
            scenario_category,
        )

    display_pronunciation_result(
        pa_report_container,
        "pa-assessment",
    )

    display_pronunciation_assessment_words(
        pa_words_container,
        "pa-text",
        "pa-assessment",
    )

    with st.expander("æŸ¥çœ‹å‘éŸ³è¯„ä¼°é›·è¾¾å›¾", expanded=False):
        item_maps = {
            "pronunciation_score": "å‘éŸ³æ€»è¯„åˆ†",
            "accuracy_score": "å‡†ç¡®æ€§è¯„åˆ†",
            "completeness_score": "å®Œæ•´æ€§è¯„åˆ†",
            "fluency_score": "æµç•…æ€§è¯„åˆ†",
            "prosody_score": "éŸµå¾‹åˆ†æ•°",
        }
        view_radar("pa-assessment", item_maps)

# endregion

# region å£è¯­è¯„ä¼°

if menu and menu.endswith("å£è¯­èƒ½åŠ›"):
    pass

# endregion

# region å†™ä½œè¯„ä¼°

if menu and menu.endswith("å†™ä½œè¯„ä¼°"):
    pass

# endregion
